| Year       | Conference/Journal       | Title                  | Authors  | Code |Remark |
| ------------- |:-------------:|:--------------------------:|:------------:|:------------:|:------------:|
|2013|ICML|[Pseudo-Label : The Simple and Efficient Semi-Supervised Learning Method for Deep Neural Networks](http://deeplearning.net/wp-content/uploads/2013/03/pseudo_label_final.pdf)|Dong-Hyun Lee|[Pytorch Code](https://github.com/iBelieveCJM/pseudo_label-pytorch)|
|2014|NIPS|[Learning with Pseudo-Ensembles](http://papers.nips.cc/paper/5487-learning-with-pseudo-ensembles.pdf)|Philip Bachman,Ouais Alsharif,Doina Precup|[Code](https://github.com/Philip-Bachman/Pseudo-Ensembles)|
|2015|NIPS|[Semi-Supervised Learning with Ladder Networks](https://arxiv.org/pdf/1507.02672.pdf)|Antti Rasmus, Harri Valpola, Mikko Honkala,Mathias Berglund,Tapani Raiko|[Theano](https://github.com/CuriousAI/ladder), [Tensorflow](https://github.com/rinuboney/ladder)|
|2016|ICIP|[Mutual Exclusivity Loss for Semi-Supervised Deep Learning](https://arxiv.org/pdf/1606.03141.pdf)|Mehdi Sajjadi, Mehran Javanmardi, Tolga Tasdizen|
|2016|NIPS|[Regularization With Stochastic Transformations and Perturbations for Deep Semi-Supervised Learning](https://arxiv.org/abs/1606.04586)|Mehdi Sajjadi, Mehran Javanmardi, Tolga Tasdizen|[Code](https://github.com/m-sajjadi/Semi-Supervised-Learning-SparseConvNet)|
|2017|ICLR|[Temporal Ensembling for Semi-supervised Learning](https://arxiv.org/pdf/1610.02242.pdf)|Samuli Laine,Timo Aila|[Tensorflow](https://github.com/Goldesel23/Temporal-Ensembling-for-Semi-Supervised-Learning)|
|2017|NIPS|[Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results](https://arxiv.org/pdf/1703.01780.pdf)|Antti Tarvainen, Harri Valpola|[Pytorch & Tensorflow](https://github.com/CuriousAI/mean-teacher)|
|2018|IJCAI|[Tri-net for Semi-Supervised Deep Learning](https://www.ijcai.org/proceedings/2018/0278.pdf)|Dong-Dong Chen, Wei Wang, Wei Gao, Zhi-Hua Zhou||
|2018|CVPR|[Smooth Neighbors on Teacher Graphs for Semi-supervised Learning](https://arxiv.org/abs/1711.00258)|Yucen Luo, Jun Zhu, Mengxi Li, Yong Ren, Bo Zhang|[Theano](https://github.com/xinmei9322/SNTG)|
|2018|TPAMI|[Virtual Adversarial Training: A Regularization Method for Supervised and Semi-Supervised Learning](https://arxiv.org/pdf/1704.03976.pdf)|Takeru Miyato, Shin-ichi Maeda, Masanori Koyama, Shin Ishii||
|2018|AAAI|[Adversarial Dropout for Supervised and Semi-supervised Learning](https://arxiv.org/pdf/1707.03631.pdf)|Sungrae Park, Jun-Keon Park,Su-Jin Shin,Il-Chul Moon||
|2018|ECCV|[Transductive Semi-Supervised Deep Learning using Min-Max Features](http://openaccess.thecvf.com/content_ECCV_2018/papers/Weiwei_Shi_Transductive_Semi-Supervised_Deep_ECCV_2018_paper.pdf)|Weiwei Shi, Yihong Gong, Chris Ding,Zhiheng Ma,Xiaoyu Tao,Nanning Zheng||
|2019|Arxiv|[MixMatch - A Holistic Approach to Semi-Supervised Learning](https://arxiv.org/pdf/1905.02249v1.pdf)|David Berthelot, Nicholas Carlini, Ian Goodfellow, Nicolas Papernot, Avital Oliver and Colin Raffel|[Code](https://github.com/google-research/mixmatch)|
|2019|Arxiv|[Unsupervised Data Augmentation](https://arxiv.org/pdf/1904.12848.pdf)|Qizhe Xie, Zihang Dai, Eduard Hovy,Minh-Thang Luong, Quoc V. Le||
